{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dd3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed under a 3-clause BSD style license - see LICENSE.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1144f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from feupy.roi import ROI\n",
    "from feupy.target import Target\n",
    "from feupy.utils.string_handling import name_to_txt\n",
    "from feupy.scripts import gammapy_catalogs \n",
    "\n",
    "from feupy.catalog.pulsar.atnf import SourceCatalogATNF\n",
    "from feupy.catalog.lhaaso import SourceCatalogPublishNatureLHAASO\n",
    "from feupy.catalog.hawc import SourceCatalogExtraHAWC\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.units import Quantity\n",
    "\n",
    "from gammapy.utils.units import energy_unit_format\n",
    "\n",
    "from gammapy.datasets import FluxPointsDataset\n",
    "from gammapy.datasets import Datasets\n",
    "\n",
    "from gammapy.modeling.models import SkyModel, Models\n",
    "\n",
    "from gammapy.estimators import FluxPoints\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4513ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"AnalysisConfig\", \"Analysis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9797e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create a class:\n",
    "class AnalysisConfig:\n",
    "   # ADD others parameters\n",
    "   \n",
    "    # color=\"red\" # The color of the flux ponts\n",
    "    all=[]\n",
    "    @u.quantity_input(pos_ra=u.deg, pos_dec=u.deg, radius=u.deg, e_ref_min=u.eV, e_ref_max=u.eV)\n",
    "    def __init__(self, target_name: str, pos_ra, pos_dec, radius, e_ref_min=None, e_ref_max=None, catalogs_roi=None):\n",
    "       # Run validations to the received arguments\n",
    "        assert  0 <= pos_ra.value <= 360, f\"Right Ascension {pos_ra} is not in the range: (0,360) deg!\"\n",
    "        assert -90 <= pos_dec.value <= 90, f\"Declination {pos_dec} is not in the range: (-90,90) deg!\"\n",
    "\n",
    "        # Assign to self object\n",
    "        self.__target_name = target_name\n",
    "        self.position = SkyCoord(pos_ra, pos_dec) \n",
    "        self.radius = radius\n",
    "        if e_ref_min is not None:\n",
    "            self.e_ref_min = Quantity(e_ref_min, \"TeV\")\n",
    "        else: self.e_ref_min = e_ref_min\n",
    "        if e_ref_max is not None:\n",
    "            self.e_ref_max = Quantity(e_ref_max, \"TeV\")\n",
    "        else: self.e_ref_max = e_ref_max\n",
    "        self.energy_range = [self.e_ref_min, self.e_ref_max]\n",
    "        self.target = Target(self.__target_name, self.position.ra, self.position.dec)\n",
    "        self.roi = ROI(self.__target_name, self.position.ra, self.position.dec, self.radius)\n",
    "        \n",
    "        # Actions to execute\n",
    "        AnalysisConfig.all.append(self)\n",
    "    \n",
    "    @property\n",
    "    # Property Decorator=Read-Only Attribute\n",
    "    def info(self):\n",
    "        info={}\n",
    "        info[\"target_name\"] = self.target_name\n",
    "        info[\"position\"] = self.position\n",
    "        info[\"radius\"] = self.radius\n",
    "        info[\"energy_range\"] = self.energy_range\n",
    "        return info    \n",
    "    \n",
    "    @property\n",
    "    def target_name(self):\n",
    "        return self.__target_name\n",
    "\n",
    "    def __repr__(self):\n",
    "        ss = f\"{self.__class__.__name__}(\"\n",
    "        ss += f\"target_name={self.__target_name}, \"\n",
    "        ss += \"pos_ra=Quantity('{:.2f}'), \".format(self.position.ra).replace(' ', '')\n",
    "        ss += \"pos_dec=Quantity('{:.2f}'), \".format(self.position.dec).replace(' ', '')\n",
    "        ss += \"radius=Quantity('{:.2f}'), \".format(self.radius).replace(' ', '')\n",
    "        if self.e_ref_min is None: ss += \"e_ref_min=None, \"\n",
    "        else: ss += \"e_ref_min=Quantity('{}'), \".format(energy_unit_format(self.e_ref_min).replace(' ', ''))\n",
    "        if self.e_ref_max is None: ss += \"e_ref_max=None)\"\n",
    "        else: ss += \"e_ref_max=Quantity('{}'))\".format(energy_unit_format(self.e_ref_max).replace(' ', ''))\n",
    "        return ss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45704a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis:\n",
    "    \"\"\"Config-driven high level analysis interface.\n",
    "\n",
    "    It is initialized by default with a set of configuration parameters and values declared in\n",
    "    an internal high level interface model, though the user can also provide configuration\n",
    "    parameters passed as a nested dictionary at the moment of instantiation. In that case these\n",
    "    parameters will overwrite the default values of those present in the configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict or `~gammapy.analysis.AnalysisConfig`\n",
    "        Configuration options following `AnalysisConfig` schema.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.catalogs = None\n",
    "        self.datasets = None\n",
    "        self.sources = None\n",
    "        self.models = None\n",
    "        self.pulsars = None\n",
    "        self.dict_roi = None\n",
    "        self.df_roi = None\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        \"\"\"Analysis configuration as an `~feupy.analysis.counterparts.AnalysisConfig` object.\"\"\"\n",
    "        return self._config\n",
    "\n",
    "    @config.setter\n",
    "    def config(self, value):\n",
    "        if isinstance(value, AnalysisConfig):\n",
    "            self._config = value\n",
    "        else:\n",
    "            raise TypeError(\"config must be AnalysisConfig.\")\n",
    "            \n",
    "    def run(self):\n",
    "        self._get_catalogs()\n",
    "        self._get_datasets()\n",
    "        self._get_dict_roi()\n",
    "        self._get_df_roi()\n",
    "        \n",
    "    def _get_catalogs(self):\n",
    "        _catalogs = []\n",
    "        catalogs_roi = []\n",
    "        \n",
    "        position = self.config.roi.position \n",
    "        radius = self.config.roi.radius \n",
    "\n",
    "        _catalogs.extend(gammapy_catalogs.load_all_catalogs())\n",
    "        _catalogs.append(SourceCatalogExtraHAWC())\n",
    "        _catalogs.append(SourceCatalogPublishNatureLHAASO())\n",
    "        _catalogs.append(SourceCatalogATNF())\n",
    "\n",
    "\n",
    "        n_tot = len(_catalogs)\n",
    "        for catalog in _catalogs:        \n",
    "            # Selects only sources within the region of interest. \n",
    "            separation = position.separation(catalog.positions)\n",
    "\n",
    "            mask_roi = separation < radius\n",
    "\n",
    "            if len(catalog[mask_roi].table):\n",
    "                catalogs_roi.append(catalog[mask_roi])\n",
    "            else:\n",
    "                pass\n",
    "#               catalogs_roi_no.append(f\"{catalog.tag}: {catalog.description}\")\n",
    "        self.catalogs = catalogs_roi\n",
    "  \n",
    "    def _get_datasets(self):\n",
    "        \"\"\"\n",
    "        Select a catalog subset (only sources within a region of interest)\n",
    "        \"\"\"\n",
    "\n",
    "        datasets = Datasets() # global datasets object\n",
    "        models = Models()  # global models object\n",
    "        sources = [] # global sources object\n",
    "        pulsars = [] # global pulsars object\n",
    "        n_sources = 0 # number of sources\n",
    "        n_flux_points = 0 # number of flux points tables\n",
    "        \n",
    "        for catalog in self.catalogs:\n",
    "            cat_tag = catalog.tag\n",
    "            for source in catalog:\n",
    "                n_sources += 1   \n",
    "                source_name = source.name            \n",
    "                if cat_tag == \"ATNF\":\n",
    "                    pulsars.append(source)\n",
    "                else:\n",
    "                    try:\n",
    "                        flux_points = source.flux_points\n",
    "\n",
    "                        spectral_model = source.spectral_model()\n",
    "                        spectral_model_tag = spectral_model.tag[1]\n",
    "\n",
    "                        if cat_tag == 'gamma-cat' or cat_tag == 'hgps':\n",
    "                            dataset_name = f'{source_name}: {cat_tag}'\n",
    "                        else: dataset_name = source_name\n",
    "\n",
    "                        file_name = name_to_txt(dataset_name)\n",
    "\n",
    "                        model = SkyModel(\n",
    "                            name=f\"{file_name}_{spectral_model_tag}\",\n",
    "                            spectral_model=spectral_model,\n",
    "                            datasets_names=dataset_name\n",
    "                        )\n",
    "\n",
    "                        dataset = FluxPointsDataset(\n",
    "                            models=model,\n",
    "                            data=flux_points, \n",
    "                            name=dataset_name   \n",
    "                        )\n",
    "\n",
    "                        if any([self.config.e_ref_min !=  None, self.config.e_ref_max !=  None]):\n",
    "                            dataset = self._cut_energy_flux_points(dataset)\n",
    "\n",
    "                        n_flux_points += 1\n",
    "                        models.append(model)  # Add the model to models()\n",
    "\n",
    "                        sources.append(source)\n",
    "                        datasets.append(dataset)\n",
    "\n",
    "                    except Exception as error:\n",
    "                        # By this way we can know about the type of error occurring\n",
    "                        print(f'The error is: ({source_name}) {error}') \n",
    "\n",
    "        datasets.models = models\n",
    "        \n",
    "        self.pulsars = pulsars\n",
    "        self.sources = sources\n",
    "        self.datasets = datasets\n",
    "        self.models = models\n",
    "        \n",
    "        print(f\"Total number of gammapy sources: {n_sources-len(pulsars)}\")\n",
    "        print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "        print(f\"Total number of pulsars: {len(pulsars)}\")\n",
    "        \n",
    "    def _cut_energy_flux_points(self, dataset):\n",
    "        _datasets = Datasets()\n",
    "        e_ref_min = self.config.e_ref_min\n",
    "        e_ref_max = self.config.e_ref_max\n",
    "\n",
    "        flux_points = dataset.data\n",
    "        models = dataset.models[0]      \n",
    "        ds_name = dataset.name\n",
    "\n",
    "        if e_ref_min != None:\n",
    "            mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "            for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "                if e_ref >= e_ref_min:\n",
    "                    mask_energy[m] = True\n",
    "\n",
    "            flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "            flux_points = FluxPoints.from_table(flux_points_mask)\n",
    "\n",
    "        if e_ref_max != None:\n",
    "            mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "            for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "                if e_ref <= e_ref_max:\n",
    "                    mask_energy[m] = True\n",
    "\n",
    "            flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "            flux_points = FluxPoints.from_table(flux_points_mask)     \n",
    "\n",
    "        return FluxPointsDataset(models=models, data=flux_points, name=ds_name)\n",
    "     \n",
    "    def _get_dict_roi(self):\n",
    "        _dict_roi = {}\n",
    "\n",
    "        roi_pos = self.config.roi.position \n",
    "        radius_roi = self.config.roi.radius \n",
    "\n",
    "        _sources = self.sources.copy()\n",
    "        _sources.extend(self.pulsars)\n",
    "        for index, source in enumerate(_sources):\n",
    "            source_pos = source.position\n",
    "            sep = source.position.separation(roi_pos).deg\n",
    "            if index < len(self.datasets):\n",
    "                name = self.datasets[index].name\n",
    "            else: name = source.name\n",
    "            _dict_roi[name] = {\n",
    "                'position': source_pos,\n",
    "                'separation':sep\n",
    "            }\n",
    "\n",
    "        self.dict_roi = _dict_roi\n",
    "        \n",
    "    def _get_df_roi(self):\n",
    "        _dict = self.dict_roi\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"Source name\"] = _dict.keys()\n",
    "        df_ra = []\n",
    "        df_dec = []\n",
    "        df_sep = []\n",
    "\n",
    "        for index, name in enumerate(_dict.keys()):\n",
    "            df_ra.append(_dict[name][\"position\"].ra.deg)\n",
    "            df_dec.append(_dict[name][\"position\"].dec.deg)\n",
    "            df_sep.append(_dict[name][\"separation\"])\n",
    "\n",
    "        df[\"RA(deg)\"] = df_ra\n",
    "        df[\"dec.(deg)\"] = df_dec\n",
    "        df[\"Sep.(deg)\"] = df_sep\n",
    "        self.df_roi = df\n",
    "        \n",
    "    def _create_roi_name(self): \n",
    "        \"\"\" ... \"\"\"\n",
    "        ss = f\"{self.config.target_name}\"\n",
    "        ss += \"_roi_{:.2f}\".format(self.config.radius).replace(' ', '')\n",
    "        if self.config.e_ref_min is None: ss += \"\"\n",
    "        else: ss += \"_e_ref_min_{}\".format(energy_unit_format(self.config.e_ref_min).replace(' ', ''))\n",
    "        if self.config.e_ref_max is None: ss += \"\"\n",
    "        else: ss += \"_e_ref_max_{}\".format(energy_unit_format(self.config.e_ref_max).replace(' ', ''))\n",
    "        return ss\n",
    "    \n",
    "    def create_analysis_path(self): \n",
    "        \"\"\" ... \"\"\"\n",
    "        return Path(f\"analysis_roi/{self._create_roi_name()}\")\n",
    "\n",
    "    def write_datasets_models(self, overwrite=True):\n",
    "        \"\"\"Write Datasets and Models to YAML file.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            overwrite : bool, optional\n",
    "                Overwrite existing file. Default is True.\n",
    "            \"\"\"\n",
    "\n",
    "        path_file = Path(f\"{self.create_analysis_path()}/datasets\")\n",
    "        path_file.mkdir(parents=True, exist_ok=True)\n",
    "        self.datasets.write(filename=f\"{path_file}/datasets.yaml\", filename_models=f\"{path_file}/models.yaml\", overwrite=overwrite)\n",
    "    \n",
    "    def read_datasets_models(self):\n",
    "        \"\"\"Read Datasets and Models from YAML file.\"\"\"\n",
    "\n",
    "        path_file = Path(f\"{self.create_analysis_path()}/datasets\")\n",
    "#         path_file.mkdir(parents=True, exist_ok=True)\n",
    "        return Datasets.read(filename=f\"{path_file}/datasets.yaml\", filename_models=f\"{path_file}/models.yaml\")\n",
    "#     def read_datasets_models():\n",
    "#         path_file = Path(f\"{PATH_ANALYSIS}/datasets\")\n",
    "#         path_file.mkdir(parents=True, exist_ok=True)\n",
    "#         return Datasets.read(filename=f\"{path_file}/datasets.yaml\", filename_models=f\"{path_file}/models.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d81cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To save only the models\n",
    "# models_3fhl.write(\"3fhl_models.yaml\", overwrite=True)\n",
    "\n",
    "# # To save datasets and models\n",
    "# datasets.write(\n",
    "#     filename=\"datasets-gc.yaml\", filename_models=\"models_gc.yaml\", overwrite=True\n",
    "# )\n",
    "\n",
    "# # To read only models\n",
    "# models = Models.read(\"3fhl_models.yaml\")\n",
    "# print(models)\n",
    "\n",
    "# # To read datasets with models\n",
    "# datasets_read = Datasets.read(\"datasets-gc.yaml\", filename_models=\"models_gc.yaml\")\n",
    "# print(datasets_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c1b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924c5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_analysis_confg():\n",
    "    return AnalysisConfig(\n",
    "        \"LHAASO J1825-1326\", \n",
    "        276.45* u.Unit('deg'), \n",
    "        -13.45* u.Unit('deg'),\n",
    "        1* u.Unit('deg'),\n",
    "        1* u.Unit('erg')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a982c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd551f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
